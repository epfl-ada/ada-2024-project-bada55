{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f19b5a00-d181-426d-baa8-0591c6ed4df7",
   "metadata": {},
   "source": [
    "# NOTEBOOK TO PREPROCESS THE DATA (then used for the project accomplishment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b13364f-5128-4ceb-83b9-3a6fba19cb48",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **INFORMATIONS ON THE CSVs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb650e4-cb35-4227-a3cd-6851911d1af3",
   "metadata": {},
   "source": [
    "*Data*: BeerAdvocate / RateBeer / matched_beer_data\n",
    "\n",
    "*Difference ratings-reviews*: **reviews.txt** appears to be a subset of **ratings.txt** because the latter also has the review column (True or False) and **reviews.txt** is the set of all ratings that are True.\n",
    "\n",
    "*Code to print .txt*: \n",
    "* \"\"\"with open(BA_REVIEWS_DATASET, 'r', encoding='utf-8') as file:\n",
    "    for _ in range(16):\n",
    "        print(file.readline())\"\"\"\n",
    "* \"\"\"with open(BA_RATINGS_DATASET, 'r', encoding='utf-8') as file:\n",
    "    for _ in range(17):\n",
    "        print(file.readline())\"\"\"\n",
    "* !head Data/BeerAdvocate/ratings.txt/ratings.txt\n",
    "* \"\"\"from collections import deque\n",
    "n_last_lines = 10\n",
    "with open(BA_REVIEWS_DATASET, 'r', encoding='utf-8') as file:\n",
    "    last_lines = deque(file, maxlen=n_last_lines)\n",
    "for line in last_lines:\n",
    "    print(line.strip())\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad28347-8110-48fd-be40-eaa21f3a1e0d",
   "metadata": {},
   "source": [
    "### BeerAdvocate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994460dd-1ff9-49ef-827b-f9878e840375",
   "metadata": {},
   "source": [
    "**beers.csv**\n",
    "* beer_id\n",
    "* beer_name\n",
    "* brewery_id\n",
    "* brewery_name\n",
    "* style\n",
    "* nbr_ratings\n",
    "* nbr_reviews\n",
    "* avg\n",
    "* ba_score\n",
    "* bros_score\n",
    "* abv\n",
    "* avg_computed\n",
    "* zscore\n",
    "* nbr_matched_valid_ratings\n",
    "* avg_matched_valid_ratings\n",
    "\n",
    "**breweries.csv**\n",
    "* id,\n",
    "* location\n",
    "* name\n",
    "* nbr_beers\n",
    "\n",
    "**users.csv**\n",
    "* nbr_ratings\n",
    "* nbr_reviews\n",
    "* user_id\n",
    "* user_name\n",
    "* joined\n",
    "* location\n",
    "\n",
    "**ratings.txt** (line format i.e. Header=None)\n",
    "* beer_name\n",
    "* beer_id\n",
    "* brewery_name\n",
    "* brewery_id\n",
    "* style\n",
    "* abv\n",
    "* date\n",
    "* user_name\n",
    "* user_id\n",
    "* appearance\n",
    "* aroma\n",
    "* palate\n",
    "* taste\n",
    "* overall\n",
    "* rating\n",
    "* text\n",
    "* review: *True or False*\n",
    "\n",
    "**reviews.txt** (line format i.e. Header=None, subset of **ratings.txt**)\n",
    "* beer_name\n",
    "* beer_id\n",
    "* brewery_name\n",
    "* brewery_id\n",
    "* style\n",
    "* abv\n",
    "* date\n",
    "* user_name\n",
    "* user_id\n",
    "* appearance : *up to 5*\n",
    "* aroma : *up to 5*\n",
    "* palate : *up to 5*\n",
    "* taste : *up to 5*\n",
    "* overall : *up to 5*\n",
    "* rating : *up to 5, unkown formula but different weights for each parameter*\n",
    "* text\n",
    "\n",
    "----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e033d0c-f20c-44b8-bff0-1af5be077643",
   "metadata": {},
   "source": [
    "### RateBeer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2559dc1b-7f7a-4020-808a-a2d7447455ae",
   "metadata": {},
   "source": [
    "**beers.csv**\n",
    "* beer_id\n",
    "* beer_name\n",
    "* brewery_id\n",
    "* brewery_name\n",
    "* style\n",
    "* nbr_ratings\n",
    "* overall_score\n",
    "* style_score\n",
    "* avg\n",
    "* abv\n",
    "* avg_computed\n",
    "* zscore\n",
    "* nbr_matched_valid_ratings\n",
    "* avg_matched_valid_ratings\n",
    "\n",
    "**breweries.csv**\n",
    "* id\n",
    "* location\n",
    "* name\n",
    "* nbr_beers\n",
    "\n",
    "**users.csv**\n",
    "* nbr_ratings\n",
    "* user_id\n",
    "* user_name\n",
    "* joined\n",
    "* location\n",
    "\n",
    "**ratings.txt = reviews.txt** (line format i.e. Header=None)\n",
    "* beer_name\n",
    "* beer_id\n",
    "* brewery_name\n",
    "* brewery_id\n",
    "* style\n",
    "* abv\n",
    "* date\n",
    "* user_name\n",
    "* user_id\n",
    "* appearance : *up to 5*\n",
    "* aroma : *up to 10*\n",
    "* palate (=mouthfeel) : *up to 5*\n",
    "* taste : *up to 10*\n",
    "* overall : *up to 20*\n",
    "* rating : *up to 50 (sum of all previous) then divided by 10 --> up to 5*\n",
    "* text\n",
    "\n",
    "----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7d031d-d98b-4aed-9785-0cce90e4a6d7",
   "metadata": {},
   "source": [
    "### matched_beer_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b8aeb9-927d-4238-867e-e59ac70f1b01",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**beers.csv**\n",
    "#### ba:\n",
    "* abv\n",
    "* avg\n",
    "* avg_computed\n",
    "* avg_matched_valid_ratings\n",
    "* ba_score\n",
    "* beer_id\n",
    "* beer_name\n",
    "* beer_wout_brewery_name\n",
    "* brewery_id\n",
    "* brewery_name\n",
    "* bros_score\n",
    "* nbr_matched_valid_ratings\n",
    "* nbr_ratings\n",
    "* nbr_reviews\n",
    "* style\n",
    "* zscore\n",
    "#### rb:\n",
    "* abv\n",
    "* avg\n",
    "* avg_computed\n",
    "* avg_matched_valid_ratings\n",
    "* beer_id\n",
    "* beer_name\n",
    "* beer_wout_brewery_name\n",
    "* brewery_id\n",
    "* brewery_name\n",
    "* nbr_matched_valid_ratings\n",
    "* nbr_ratings\n",
    "* overall_score\n",
    "* style\n",
    "* style_score\n",
    "* zscore\n",
    "#### scores:\n",
    "* diff\n",
    "* sim\n",
    "\n",
    "**breweries.csv**\n",
    "#### ba:\n",
    "* id\n",
    "* location\n",
    "* name\n",
    "* nbr_beers\n",
    "#### rb:\n",
    "* id\n",
    "* location\n",
    "* name\n",
    "* nbr_beers\n",
    "#### scores:\n",
    "* diff\n",
    "* sim\n",
    "\n",
    "**ratings.csv**\n",
    "#### ba:\n",
    "* abv\n",
    "* appearance\n",
    "* aroma\n",
    "* beer_id\n",
    "* beer_name\n",
    "* brewery_id\n",
    "* brewery_name\n",
    "* date\n",
    "* overall\n",
    "* palate\n",
    "* rating\n",
    "* review\n",
    "* style\n",
    "* taste\n",
    "* text\n",
    "* user_id\n",
    "* user_name\n",
    "#### rb:\n",
    "* abv\n",
    "* appearance\n",
    "* aroma\n",
    "* beer_id\n",
    "* beer_name\n",
    "* brewery_id\n",
    "* brewery_name\n",
    "* date\n",
    "* overall\n",
    "* palate\n",
    "* rating\n",
    "* style\n",
    "* taste\n",
    "* text\n",
    "* user_id\n",
    "* user_name\n",
    "\n",
    "\n",
    "**users_approx.csv**\n",
    "#### ba:\n",
    "* joined\n",
    "* location\n",
    "* nbr_ratings\n",
    "* nbr_reviews\n",
    "* user_id\n",
    "* user_name\n",
    "* user_name_lower\n",
    "#### rb:\n",
    "* joined\n",
    "* location\n",
    "* nbr_ratings\n",
    "* user_id\n",
    "* user_name\n",
    "* user_name_lower\n",
    "#### scores:\n",
    "* sim\n",
    "\n",
    "**users.csv** (is a subset of **users_approx** --> it is composed of users from **users_approx** where `sim` closed to 1)\n",
    "#### ba:\n",
    "* joined\n",
    "* location\n",
    "* nbr_ratings\n",
    "* nbr_reviews\n",
    "* user_id\n",
    "* user_name\n",
    "* user_name_lower\n",
    "#### rb:\n",
    "* joined\n",
    "* location\n",
    "* nbr_ratings\n",
    "* user_id\n",
    "* user_name\n",
    "* user_name_lower\n",
    "\n",
    "----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c65d4-a866-4f6c-8d4d-c9cbf1f37c64",
   "metadata": {},
   "source": [
    "## **LOADING DATAs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a3e5a76-1c9a-43cc-8ecd-b4f088268654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a91fbe6-cbce-4e5a-8700-68f15e493664",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../../data/'\n",
    "BEER_ADVOCATE_FOLDER = DATA_FOLDER + 'BeerAdvocate/' #BA\n",
    "RATE_BEER_FOLDER = DATA_FOLDER + 'RateBeer/' #RB\n",
    "\n",
    "BA_RATINGS_DATASET = BEER_ADVOCATE_FOLDER + 'ratings.txt/' + \"ratings.txt\"\n",
    "BA_REVIEWS_DATASET = BEER_ADVOCATE_FOLDER + 'reviews.txt/' + \"reviews.txt\"\n",
    "\n",
    "RB_RATINGS_DATASET = RATE_BEER_FOLDER + 'ratings.txt/' + \"ratings.txt\"\n",
    "RB_REVIEWS_DATASET = RATE_BEER_FOLDER + 'reviews.txt/' + \"ratings.txt\"\n",
    "\n",
    "BA_USERS_DATASET = BEER_ADVOCATE_FOLDER + \"users.csv\"\n",
    "RB_USERS_DATASET = RATE_BEER_FOLDER + \"users.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3fd21c9-1aeb-458d-a6ca-f869b95ea2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_users = pd.read_csv(BA_USERS_DATASET)\n",
    "rb_users = pd.read_csv(RB_USERS_DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f42529-7cc8-476d-85cd-6eb2badb3498",
   "metadata": {},
   "source": [
    "## **PROCESSING BEERADVOCATE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b08d2-bde4-4b05-a489-2b805f2ac1dc",
   "metadata": {},
   "source": [
    "### users.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01c8863c-3d7c-4858-b161-17d54b2402b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_users_joined = ba_users.copy()\n",
    "ba_users_joined = ba_users_joined.drop(['nbr_ratings', 'nbr_reviews', 'user_name', 'location'], axis= 1)\n",
    "ba_users_joined = ba_users_joined.dropna()\n",
    "# remove duplicates\n",
    "ba_users_joined = ba_users_joined.drop_duplicates(subset='user_id', keep='first')  # keep the first occurrence of each duplicate\n",
    "ba_users_joined['joined'] = pd.to_datetime(ba_users_joined['joined'], unit='s')\n",
    "ba_users_joined['user_id'] = ba_users_joined['user_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a457d05-0d26-4191-9944-bff108cf335f",
   "metadata": {},
   "source": [
    "### ratings.csv / reviews.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a7544f-45f2-420e-bb27-94f2034f691b",
   "metadata": {},
   "source": [
    "ratings.txt != reviews.txt\n",
    "\n",
    "ratings :\n",
    "[151 074 576 lines i.e. 151 074 576/18 = 8 393 032 reviews]\n",
    "\n",
    "reviews :\n",
    "[4 4022 962 lines i.e. 44 022 962/17 = 2 589 586 reviews]\n",
    "\n",
    "----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b8f76f-0cb6-49f6-9b83-f574e37a7c39",
   "metadata": {},
   "source": [
    "Treatment of .txt to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58fe8df7-8216-4344-b20a-8555be4ea3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ../../generated/ba_chunks/ba_reviews_chunk_0.parquet\n",
      "Saved ../../generated/ba_chunks/ba_reviews_chunk_1.parquet\n",
      "Saved ../../generated/ba_chunks/ba_reviews_chunk_2.parquet\n",
      "Saving done\n"
     ]
    }
   ],
   "source": [
    "columns = ['beer_name', 'beer_id', 'brewery_name', 'brewery_id', 'style', 'abv', 'date', \n",
    "           'user_name', 'user_id', 'appearance', 'aroma', 'palate', 'taste', 'overall', \n",
    "           'rating', 'text']\n",
    "chunk_size = 1_000_000\n",
    "data = []\n",
    "entry_count = 0\n",
    "chunk_count = 0\n",
    "current_entry = {}\n",
    "\n",
    "with open(BA_REVIEWS_DATASET, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "                key, value = line.split(':', 1)\n",
    "                key = key.strip()\n",
    "                value = value.strip()\n",
    "                current_entry[key] = value\n",
    "        else:\n",
    "            if current_entry:\n",
    "                data.append(current_entry)\n",
    "                current_entry = {}\n",
    "                entry_count += 1\n",
    "\n",
    "                # Save chunk when reaching chunk size\n",
    "                if entry_count >= chunk_size:\n",
    "                    chunk_df = pd.DataFrame(data, columns=columns)\n",
    "                    chunk_file_path = f\"../../generated/ba_chunks/ba_reviews_chunk_{chunk_count}.parquet\"\n",
    "                    chunk_df.to_parquet(chunk_file_path)\n",
    "                    print(f\"Saved {chunk_file_path}\")\n",
    "                    data = []\n",
    "                    entry_count = 0\n",
    "                    chunk_count += 1\n",
    "                    \n",
    "# Process any remaining entries after the loop\n",
    "if data:\n",
    "    chunk_df = pd.DataFrame(data, columns=columns)\n",
    "    chunk_file_path = f\"../../generated/ba_chunks/ba_reviews_chunk_{chunk_count}.parquet\"\n",
    "    chunk_df.to_parquet(chunk_file_path)\n",
    "    print(f\"Saved {chunk_file_path}\")\n",
    "\n",
    "print('Saving done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07090ed4-d058-44e5-83f7-1c0297446f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_chunk_files = glob.glob(\"../../generated/ba_chunks/ba_reviews_chunk_*.parquet\")\n",
    "ba_reviews = pd.concat([pd.read_parquet(ba_chunk) for ba_chunk in ba_chunk_files], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eac67032-e1c5-4901-ab47-5536eccd41d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is clean, with no missing values.\n"
     ]
    }
   ],
   "source": [
    "empty_text = ba_reviews['text'] == ''\n",
    "ba_reviews.drop(ba_reviews[empty_text].index, inplace= True)\n",
    "missing_values = np.where(pd.isnull(ba_reviews))\n",
    "if missing_values[0].size == 0:\n",
    "    print(\"The dataset is clean, with no missing values.\")\n",
    "else:\n",
    "    print(\"The dataset has missing values at:\")\n",
    "    print(\"Row indices:\", missing_values[0])\n",
    "    print(\"Column indices:\", missing_values[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb04200-7685-49eb-9a59-d7eb356569d7",
   "metadata": {},
   "source": [
    "Only keep users' ratings where we have the informations about when user has joined the platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92d05da4-3820-4547-a294-64c776a3a359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before keeping ratings from users in users_joined: (2589584, 16)\n",
      "Shape after keeping ratings from users in users_joined: (2501212, 16)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape before keeping ratings from users in users_joined: {ba_reviews.shape}\")\n",
    "ba_reviews = ba_reviews[ba_reviews['user_id'].isin(ba_users_joined['user_id'])]\n",
    "print(f\"Shape after keeping ratings from users in users_joined: {ba_reviews.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9241918-9207-487b-8281-e14acf52f66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(set(ba_reviews['user_id']).issubset(set(ba_users_joined['user_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb33848d-4250-4a9f-b2a0-7b6eef1a199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_numeric = ['beer_id', 'brewery_id', 'abv', 'date', 'appearance', 'aroma', 'palate', 'taste', 'overall', 'rating']\n",
    "ba_reviews[cols_to_numeric] = ba_reviews[cols_to_numeric].apply(pd.to_numeric, errors = 'coerce')\n",
    "ba_reviews['date'] = pd.to_datetime(ba_reviews['date'], unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ca7c3e-4498-46fd-b930-f3db4842dbef",
   "metadata": {},
   "source": [
    "## **PROCESSING RATEBEER**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc07a30e-3c36-4027-9da9-f248c119674a",
   "metadata": {},
   "source": [
    "## users.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "287dc013-c5b7-40c0-a448-d0a557f5445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_users_joined = rb_users.copy()\n",
    "rb_users_joined = rb_users_joined.drop(['nbr_ratings', 'user_name', 'location'], axis= 1)\n",
    "rb_users_joined = rb_users_joined.dropna()\n",
    "# remove duplicates\n",
    "rb_users_joined = rb_users_joined.drop_duplicates(subset='user_id', keep='first')  # keep the first occurrence of each duplicate\n",
    "rb_users_joined['joined'] = pd.to_datetime(rb_users_joined['joined'], unit='s')\n",
    "rb_users_joined['user_id'] = rb_users_joined['user_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f549f982-d1be-4d9e-89a9-434ef25cff0c",
   "metadata": {},
   "source": [
    "### ratings.csv / reviews.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4df893b-097d-4f58-a2bb-a143411147e2",
   "metadata": {},
   "source": [
    "ratings.txt = reviews.txt (i.e. no difference for this dataset)\n",
    "\n",
    "[121 075 258 lines i.e. 121075258/17 = 7 122 074 review]\n",
    "\n",
    "----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0b08c7-9a43-4801-9e7b-d486efbf1bb7",
   "metadata": {},
   "source": [
    "Treatment of .txt to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b8bbfdc-38c9-4593-8e41-1a2fa92ad968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ../../generated/rb_chunks/rb_reviews_chunk_0.parquet\n",
      "Saved ../../generated/rb_chunks/rb_reviews_chunk_1.parquet\n",
      "Saved ../../generated/rb_chunks/rb_reviews_chunk_2.parquet\n",
      "Saved ../../generated/rb_chunks/rb_reviews_chunk_3.parquet\n",
      "Saved ../../generated/rb_chunks/rb_reviews_chunk_4.parquet\n",
      "Saved ../../generated/rb_chunks/rb_reviews_chunk_5.parquet\n",
      "Saved ../../generated/rb_chunks/rb_reviews_chunk_6.parquet\n",
      "Saved ../../generated/rb_chunks/rb_reviews_chunk_7.parquet\n",
      "Saving done\n"
     ]
    }
   ],
   "source": [
    "columns = ['beer_name', 'beer_id', 'brewery_name', 'brewery_id', 'style', 'abv', 'date', \n",
    "           'user_name', 'user_id', 'appearance', 'aroma', 'palate', 'taste', 'overall', \n",
    "           'rating', 'text']\n",
    "chunk_size = 1_000_000\n",
    "data = []\n",
    "entry_count = 0\n",
    "chunk_count = 0\n",
    "current_entry = {}\n",
    "\n",
    "with open(RB_REVIEWS_DATASET, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "                key, value = line.split(':', 1)\n",
    "                key = key.strip()\n",
    "                value = value.strip()\n",
    "                current_entry[key] = value\n",
    "        else:\n",
    "            if current_entry:\n",
    "                data.append(current_entry)\n",
    "                current_entry = {}\n",
    "                entry_count += 1\n",
    "\n",
    "                # Save chunk when reaching chunk size\n",
    "                if entry_count >= chunk_size:\n",
    "                    chunk_df = pd.DataFrame(data, columns=columns)\n",
    "                    chunk_file_path = f\"../../generated/rb_chunks/rb_reviews_chunk_{chunk_count}.parquet\"\n",
    "                    chunk_df.to_parquet(chunk_file_path)\n",
    "                    print(f\"Saved {chunk_file_path}\")\n",
    "                    data = []\n",
    "                    entry_count = 0\n",
    "                    chunk_count += 1\n",
    "                    \n",
    "# Process any remaining entries after the loop\n",
    "if data:\n",
    "    chunk_df = pd.DataFrame(data, columns=columns)\n",
    "    chunk_file_path = f\"../../generated/rb_chunks/rb_reviews_chunk_{chunk_count}.parquet\"\n",
    "    chunk_df.to_parquet(chunk_file_path)\n",
    "    print(f\"Saved {chunk_file_path}\")\n",
    "\n",
    "print('Saving done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14a931d9-978f-4207-9ad5-6bb343e6737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_chunk_files = glob.glob(\"../../generated/rb_chunks/rb_reviews_chunk_*.parquet\")\n",
    "rb_reviews = pd.concat([pd.read_parquet(rb_chunk) for rb_chunk in rb_chunk_files], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "443901c7-5e8a-400d-a11d-0c7014c23f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is clean, with no missing values.\n"
     ]
    }
   ],
   "source": [
    "empty_text = rb_reviews['text'] == ''\n",
    "rb_reviews.drop(rb_reviews[empty_text].index, inplace= True)\n",
    "np.where(pd.isnull(rb_reviews))\n",
    "if missing_values[0].size == 0:\n",
    "    print(\"The dataset is clean, with no missing values.\")\n",
    "else:\n",
    "    print(\"The dataset has missing values at:\")\n",
    "    print(\"Row indices:\", missing_values[0])\n",
    "    print(\"Column indices:\", missing_values[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26418c8d-0edd-4aba-933b-7137813ee854",
   "metadata": {},
   "source": [
    "Only keep users' ratings where we have the informations about when user has joined the platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b66b9fc8-8805-4dbb-b9a6-1d50fd0677ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before keeping ratings from users in users_joined: (7121626, 16)\n",
      "Shape after keeping ratings from users in users_joined: (7118976, 16)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape before keeping ratings from users in users_joined: {rb_reviews.shape}\")\n",
    "rb_reviews = rb_reviews[rb_reviews['user_id'].isin(rb_users_joined['user_id'])]\n",
    "print(f\"Shape after keeping ratings from users in users_joined: {rb_reviews.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9c6a1c7-4649-4f49-a208-1765eee5d7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(set(rb_reviews['user_id']).issubset(set(rb_users_joined['user_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62c7ed77-4da1-42fb-8820-a6e3a01fd664",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_numeric = ['beer_id', 'brewery_id', 'abv', 'date', 'appearance', 'aroma', 'palate', 'taste', 'overall', 'rating']\n",
    "rb_reviews[cols_to_numeric] = rb_reviews[cols_to_numeric].apply(pd.to_numeric, errors = 'coerce')\n",
    "rb_reviews['date'] = pd.to_datetime(rb_reviews['date'], unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b077c931-bfd2-4e80-bce2-395487dd380a",
   "metadata": {},
   "source": [
    "## **SAVING PROCESSED DFs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "295599da-55a2-4c1c-a61e-65462fad02ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_reviews.to_parquet('../../generated/new_ba_reviews.parquet')\n",
    "rb_reviews.to_parquet('../../generated/new_rb_reviews.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b9397c0-7555-4a76-989b-f1f842855022",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_users_joined.to_parquet('../../generated/ba_users_joined.parquet')\n",
    "rb_users_joined.to_parquet('../../generated/rb_users_joined.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
